1：卡发卡是一种高吞吐量的分布式发布定于消息系统，使用Scala编写；
2：Topic： kafak按照topic 分类维护消息；
3：Producer：生产消息
4：Consumer ：消费者
5：Broker：存储数据的地方
6：每一个topic 下面会维护一个或者多个分区（类似于队列）；
7：partition 分区是一个有序的message序列，这些message按照顺序添加到一个叫做commit log的文件中；
8：每隔partition中的额消息都有一个唯一的编号；称之为offerset（偏移量）；
9：当消息被消费后，offerset 会偏移
10：kafka的消息默认保留七天，消息被消费后不会立刻删除，只是偏移了1个位置；
11：kafka可以指定分区的offerset 进行消费；
12：kafka的性能与保留的数据量大小没有关系；
13：kafka的consumer对集群的影响非常少，添加一个或者减少一个consumer，对于集群或者其他消费者来说，都是没有影响的，
每个消费者维护自己的offset；
14：rocketMQ前身就是kafka
15：kafka设置分区可以调高消费者的并发量，合理的设置分区可以有效的减少消费压力；
16：log的partitions 分布在kafka集群中不同的broker，每隔broker可以请求其他备份的broker上的partition的数据；kafka集群支持配置一个
partition备份的数量；
17：kafka 一个分区只能被一个消费者消费（为了保证顺序性，硬性规定）
18：消费者消费成功返回ack（确认）状态；
19：每一个consumer都要标记自己属于哪一个 group ，message会被传递到某一个组的 一个consumer，如果所有的consumer都在一个group
下，就类似与传统的queue，如果每个消费者都有一个group，相当于 public-subscribe模型；
20：生产者将消息发送到topic中去，同时负责选择将message 发送到topic 的哪一个partition中，，可以通过round-robin做负载均衡；
也可以使用关键字进行区分，第二种方式使用的较多；
21：当一个topic创建多个分区时，如果开启了多个副本，那么就意味着 各个的分区的leader副本是不一致的，在消费消息时，不会因为一个分区挂掉了而导致
服务的不可用，进一步提高了服务的高可用性；
22：kafka 新版和旧版 因为元数据存储的地方不同，导致命令不同，例如查看组信息，新版在broker中，老版在zookeeper中
    例如：bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group testGroup  （新版）
          bin/kafka-consumer-groups.sh --zookeeper 127.0.0.1:2181 --list  （旧版）
23: 局域网通信需要关闭防火墙，看是否ping通 ，配置要改成advertised.listeners=PLAINTEXT://192.168.1.12:9092（外网监听）
24：如果要创建多个备份因子，需要zookeeper集群；否则会出现备份因子大于可用代理的问题导致无法创建topic
25：（不给消费者指定分区的情况下）一个分区只能被一个消费者消费；例如一个分区，四个消费者，那么kafka会按照算法 计算出一个消费者，然后由这个消费这消费，只要这个消费者不死亡，就会一直由他消费
    如果死亡了，重新计算出一个消费者，如果死掉了恢复了，由于算法不变，还由死而复生的消费者消费，
    无论任何情况，通过算法只能算出一个消费者消费某一个分区；
    如果消费者指定了分区，那么消费指定分区，如果多个消费者指定同一个分区，那么还会通过算法算出一个消费者去消费；
26：选举原理：当一个broker 挂掉后，通过zookeeper watch 事件通知其他broker，其他broker会在zookkeeper 创建一个共同的临时目录，里面写入自己的参选信息，通过zookeeper分布式锁
              最终只有一个broker 写入成功，那么这个broker 就是leader
27：操作命令
   a:服务端启动：bin/kafka-server-start.sh  -daemon config/server.properties 
   b:创建topic：bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
   b1:删除topic:bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test
   c:显示zookeeper节点：bin/kafka-topics.sh --list --zookeeper localhost:2181
   d:发送消息：bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
   e:消费消息：bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test   --from-beginning
   f:消费消息（新）：bin/kafka-console-consumer.sh --zookeeper 192.168.1.12:2181 --consumer-property group.id=testGroup  --topic test   --from-beginning
   g:查看组topic状态（old）：bin/kafka-topics.sh --zookeeper 192.168.1.12:2181 --topic test  --describe
   g1：查看组topic状态（new）：bin/kafka-consumer-groups.sh --bootstrap-server 192.168.1.12:9092 --describe --group testGroup
   h:查看某个consumer组：bin/kafka-consumer-groups.sh --zookeeper  192.168.1.12:2181  --describe --group testGroup	     
问题（1）：
两个消费者消费同一个topic的同一个分区，流程时怎样的，正常业务一个消息只能被一个消费者消费，
一般不会重复消费，kafka是否可以满足；
consumer有组的概念，如果每个consumer有不同的groupid，那么所有consumer都会消费，如果只有一个groupid，那么只有一个consumer会消费
并且按照顺序消费；



